created: 20140727164127192
modified: 20140727180313155
title: 9 Evaluation of R&D tax credits
type: text/vnd.tiddlywiki

''Evaluations are essential in monitoring effectiveness of R&D tax incentives. New tools are available but evaluations should not only consider goals but also full monetary and societal costs (distortion, trade-offs, @@.nolink [[compliance]]@@<<dict "compliance" "943">>).''

R&D tax credits have been evaluated in many countries using diverse methods. For the purpose of policy assessment, firms cannot legally be excluded from a tax incentive to which they are entitled. This removes the possibility of evaluating R&D tax credits by constructing a control group using randomisation techniques. Evaluations have therefore been based on the following four approaches: ''Surveys''; ''Quasi-natural experiments''; ''Techniques using statistically constructed control groups''; ''Structural econometric modelling''.

!! Surveys

The evaluations using surveys suffer from ''a number of weaknesses''. Entrepreneurs or managers might be unable accurately to assess the genuine impacts of the scheme, distinguishing these from many other possible determinants of R&D spending. @@.red-line Long-run effects might be ignored@@, especially if the survey is administered shortly after the commencement of the policy. And respondents could also have strategic reasons for overstating or understating programme impacts. Surveys, moreover, have typically been based on ''small sample sizes''.

!! Quasi-natural experiments

Another set of evaluations of R&D tax credits uses econometric techniques that exploit discontinuities in the process of administrative selection of target firms. @@.red-line If for instance there is a ceiling on the application or rate of the tax credit, then firms operating above that ceiling could be used as a control group.@@ A comparison over time can be made between the change in R&D spending among firms below the ceiling - following introduction of the scheme - and the change in R&D spending over the same period among firms above the ceiling (the so-called ‘difference in differences’ method). An evaluation of Norway's R&D tax credit followed this approach (Haegeland and Moen, 2007). That evaluation concluded that the scheme, introduced in 2002, increases private spending on R&D.

!! Techniques using statistically constructed control groups

The third evaluation approach statistically constructs a control group. Analysts have recorded observable characteristics of firms that have used the tax credit, and then identified firms that match those characteristics but did not use the tax credit. The difference in R&D spending in the two groups is attributed to the tax credit. However, even using a comprehensive set of matching criteria - such as firm turnover, age, sector of operation, geographic location, etc. - perfect comparability between the two groups is not possible. There may always be some unobserved differences between beneficiaries and non-beneficiaries that also affect the policy outcome. For instance, in all observable respects two firms may have the same probability of receiving a tax credit, but the abilities of their respective managements may differ. This might lead the managerially able firm to use the tax credit, and the managerially less able firm not to. The managerial abilities in question might also be associated with a higher propensity to innovate. Evaluations that use matching-methods also require that there be a sufficient number of firms that qualify for the tax credit but fail to apply.

!! Structural econometric modelling

A fourth approach to evaluating R&D tax credits has been structural econometric modelling. Developed by the United States' Government Accounting Office, this approach uses models of R&D investment behaviour and @@.red-line assumes that R&D spending is a function of the cost to the firm of the capital used@@. The modelling first seeks to estimate the @@.red-line sensitivity of the cost of capital used to the R&D tax credit@@. In a second step, estimates are made of the @@.red-line sensitivity of firms' R&D spending to changes in the user cost of capital@@. Lokshin and Mohnen (2009) use structural econometric modelling to assess the R&D tax credit in the Netherlands (WBSO). Their results indicate that for SMEs, each euro of the tax credit generates 0.2 of a euro in additional R&D. The figure is considerably lower in large firms, at around 0.07 of a euro.

R&D tax credits also produce outcomes other than increased R&D. These include: decisions to begin investing in R&D for the first time; changes in the productivity of R&D; changes in the wages of researchers; and social welfare improvements (taking into consideration all direct and indirect economic effects of the policy). However, these outcomes are rarely assessed in policy evaluations. Nevertheless, Mairesse and Lentile (2009) identify a number of evaluations that do consider the less-frequently assessed outcomes: in Norway, Hoegaland and Moen (2007) found that after the introduction of the R&D tax credit, firms that had not previously invested in R&D experienced a 7% increase in their ''probability of doing so''. In Canada, Czarnitzki et al (2005) found evidence both for and against the proposition that R&D tax credits generate increased productivity or profitability. And in both Norway and the Netherlands, evaluations found a ''positive but small effect'' on the wages of research workers.

Very little research exists assessing the full costs and benefits of an R&D tax credit. An exception is a study of the scheme in Canada by Parsons and Phillips (2007). This evaluation sought to separately quantify and then combine five effects of policy. The study indicates a median increase in social welfare of 11 cents for each dollar of tax credit. However, the authors observe that variations in assumptions underlying the estimates of each policy effect can lead to net outcomes that are either positive or negative, leading to the conditional conclusion that the "tax credit likely generates positive net economic benefits under a reasonable range of assumptions."

Despite the large number of evaluations, comparability across studies is @@.nolink [[hazardous]]@@<<dict "hazardous" "712">>. In part this reflects variations in method. Problems of comparability also arise because of variation in the design of tax incentive schemes. This diversity of designs and goals underscores the importance of establishing the right evaluation metrics.

<$macrocall $name="navi" title={{!!title}}/>